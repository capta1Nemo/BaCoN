Reading log from models/5_small/5_small_log.txt 

 -------- Loaded parameters:
bayesian True
test_mode False
n_test_idx 2
seed 1312
fine_tune False
one_vs_all False
c_0 ['lcdm']
c_1 ['dgp', 'fR', 'rand', 'wcdm']
dataset_balanced False
include_last False
log_path 
restore False
fname 5_small
model_name custom
my_path None
DIR data/test_data/
TEST_DIR data/test_data/
models_dir models/
save_ckpt True
out_path_overwrite False
im_depth 500
im_width 1
im_channels 4
swap_axes True
sort_labels True
normalization stdcosmo
sample_pace 4
k_max 2.5
i_max None
add_noise True
n_noisy_samples 10
add_shot True
add_sys True
sigma_sys 5.0
z_bins [0, 1, 2, 3]
n_dense 1
filters [8, 16, 32]
kernel_sizes [10, 5, 2]
strides [2, 2, 1]
pool_sizes [2, 2, 0]
strides_pooling [2, 1, 0]
add_FT_dense False
trainable False
unfreeze False
lr 0.01
drop 0.5
n_epochs 50
val_size 0.15
test_size 0.0
batch_size 2500
patience 100
GPU True
decay 0.95
BatchNorm True
group_lab_dict {'dgp': 'non_lcdm', 'fR': 'non_lcdm', 'rand': 'non_lcdm', 'wcdm': 'non_lcdm', 'lcdm': 'lcdm'}
FLAGS.one_vs_all : False
Setting save_indexes to False
Using data in the directory data/test_data/
Reading model from the directory models/

 -------- Parameters:
bayesian True
test_mode False
n_test_idx 2
seed 1312
fine_tune False
one_vs_all False
c_0 ['lcdm']
c_1 ['dgp', 'fR', 'rand', 'wcdm']
dataset_balanced False
include_last False
log_path 
restore False
fname 5_small
model_name custom
my_path None
DIR data/test_data/
TEST_DIR data/test_data/
models_dir models/
save_ckpt True
out_path_overwrite False
im_depth 500
im_width 1
im_channels 4
swap_axes True
sort_labels True
normalization stdcosmo
sample_pace 4
k_max 2.5
i_max None
add_noise True
n_noisy_samples 10
add_shot True
add_sys True
sigma_sys 5.0
z_bins [0, 1, 2, 3]
n_dense 1
filters [8, 16, 32]
kernel_sizes [10, 5, 2]
strides [2, 2, 1]
pool_sizes [2, 2, 0]
strides_pooling [2, 1, 0]
add_FT_dense False
trainable False
unfreeze False
lr 0.01
drop 0.5
n_epochs 50
val_size 0.15
test_size 0.0
batch_size 2500
patience 100
GPU True
decay 0.95
BatchNorm True
group_lab_dict {'dgp': 'non_lcdm', 'fR': 'non_lcdm', 'rand': 'non_lcdm', 'wcdm': 'non_lcdm', 'lcdm': 'lcdm'}
save_indexes False
------------ CREATING DATA GENERATORS ------------

labels : ['dgp', 'fR', 'lcdm', 'rand', 'wcdm']
Labels encoding: 
{'dgp': 0, 'fR': 1, 'lcdm': 2, 'rand': 3, 'wcdm': 4}
n_labels : 5
dgp - 2500 training examples
fR - 2500 training examples
lcdm - 2500 training examples
rand - 2500 training examples
wcdm - 2500 training examples

N. of data files: 2500
get_all_indexes labels dict: {'dgp': 0, 'fR': 1, 'lcdm': 2, 'rand': 3, 'wcdm': 4}
create_generators n_labels_eff: 5
create_generators len_c1: 1
--Train
batch_size: 2500
- Cut sample
bs: 2500
N_labels: 5
N_noise: 10
len_c1: 1
Indexes length: 2500
n_keep: 2500
Not sampling
New length: 2500
N batches: 50.0
 len_C1: 1
N indexes: 50.0
Ok.
N. of test files used: 2500
Data Generator Initialization
Using z bins [0, 1, 2, 3]
Specified k_max is 2.5
Corresponding i_max is 100
Closest k to k_max is 2.539859
New data dim: (100, 1)
Final i_max used is 100
one_vs_all: False
dataset_balanced: False
base_case_dataset: True
N. classes: 5
N. n_classes in output: 5
list_IDs length: 2500
n_indexes (n of file IDs read for each batch): 50
batch size: 2500
n_batches : 50
For each batch we read 50 file IDs
For each file ID we have 5 labels
For each ID, label we have 10 realizations of noise
In total, for each batch we have 2500 training examples
Input batch size: 2500
N of batches to cover all file IDs: 50
------------ DONE ------------

Input shape (100, 4)
------------ BUILDING MODEL ------------

Model n_classes : 5 
Features shape: (2500, 100, 4)
Labels shape: (2500, 5)
using 1D layers and 4 channels
Expected output dimension of layer conv1d_flipout: 46.0
/home/master/micromamba/envs/Bacon/lib/python3.9/site-packages/tensorflow_probability/python/layers/util.py:99: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use `layer.add_weight` method instead.
  loc = add_variable_fn(
2024-12-05 17:55:32.978521: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-12-05 17:55:32.981658: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.
/home/master/micromamba/envs/Bacon/lib/python3.9/site-packages/tensorflow_probability/python/layers/util.py:109: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use `layer.add_weight` method instead.
  untransformed_scale = add_variable_fn(
Expected output dimension of layer max_pooling1d: 23.0
Expected output dimension of layer conv1d_flipout_1: 10.0
Expected output dimension of layer max_pooling1d_1: 9.0
Expected output dimension of layer conv1d_flipout_2: 8.0
Model: "model"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_1 (InputLayer)        [(None, 100, 4)]          0         
                                                                 
2024-12-05 17:55:33.417992: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.
 conv1d_flipout (Conv1DFlipo  (None, 46, 8)            648       
 ut)                                                             
                                                                 
 max_pooling1d (MaxPooling1D  (None, 23, 8)            0         
 )                                                               
                                                                 
 batch_normalization (BatchN  (None, 23, 8)            32        
 ormalization)                                                   
                                                                 
 conv1d_flipout_1 (Conv1DFli  (None, 10, 16)           1296      
 pout)                                                           
                                                                 
 max_pooling1d_1 (MaxPooling  (None, 9, 16)            0         
 1D)                                                             
                                                                 
 batch_normalization_1 (Batc  (None, 9, 16)            64        
 hNormalization)                                                 
                                                                 
 conv1d_flipout_2 (Conv1DFli  (None, 8, 32)            2080      
 pout)                                                           
                                                                 
 batch_normalization_2 (Batc  (None, 8, 32)            128       
 hNormalization)                                                 
                                                                 
 global_average_pooling1d (G  (None, 32)               0         
 lobalAveragePooling1D)                                          
                                                                 
 dense_flipout (DenseFlipout  (None, 32)               2080      
 )                                                               
                                                                 
 batch_normalization_3 (Batc  (None, 32)               128       
 hNormalization)                                                 
                                                                 
 dense_flipout_1 (DenseFlipo  (None, 5)                325       
 ut)                                                             
                                                                 
=================================================================
Total params: 6,781
Trainable params: 6,605
Non-trainable params: 176
_________________________________________________________________
None
Computing loss for randomly initialized model...
Loss before loading weights/ 1.6777896

------------ RESTORING CHECKPOINT ------------

/home/master/micromamba/envs/Bacon/lib/python3.9/site-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.
  super(Adam, self).__init__(name, **kwargs)
Looking for ckpt in models/5_small/tf_ckpts/
Restoring checkpoint from models/5_small/tf_ckpts/ckpt-26
Loss after loading weights/ 0.18584761

WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).step
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.iter
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.beta_1
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.beta_2
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.decay
Threshold probability for classification: 0.5 
Accuracy on 0 batch using median of sampled probabilities: 0.9568 %
Accuracy on 0 batch using median of sampled probabilities, not considering unclassified examples: 0.96412736 %
Accuracy on 1 batch using median of sampled probabilities: 0.9248 %
Accuracy on 1 batch using median of sampled probabilities, not considering unclassified examples: 0.9303823 %
Accuracy on 2 batch using median of sampled probabilities: 0.9192 %
Accuracy on 2 batch using median of sampled probabilities, not considering unclassified examples: 0.92923576 %
Accuracy on 3 batch using median of sampled probabilities: 0.9232 %
Accuracy on 3 batch using median of sampled probabilities, not considering unclassified examples: 0.9313963 %
Accuracy on 4 batch using median of sampled probabilities: 0.9112 %
Accuracy on 4 batch using median of sampled probabilities, not considering unclassified examples: 0.91743857 %
Accuracy on 5 batch using median of sampled probabilities: 0.9092 %
Accuracy on 5 batch using median of sampled probabilities, not considering unclassified examples: 0.91875505 %
Accuracy on 6 batch using median of sampled probabilities: 0.9188 %
Accuracy on 6 batch using median of sampled probabilities, not considering unclassified examples: 0.9250906 %
Accuracy on 7 batch using median of sampled probabilities: 0.9384 %
Accuracy on 7 batch using median of sampled probabilities, not considering unclassified examples: 0.94179046 %
Accuracy on 8 batch using median of sampled probabilities: 0.944 %
Accuracy on 8 batch using median of sampled probabilities, not considering unclassified examples: 0.95122933 %
Accuracy on 9 batch using median of sampled probabilities: 0.9208 %
Accuracy on 9 batch using median of sampled probabilities, not considering unclassified examples: 0.93311715 %
Accuracy on 10 batch using median of sampled probabilities: 0.9492 %
Accuracy on 10 batch using median of sampled probabilities, not considering unclassified examples: 0.9556987 %
Accuracy on 11 batch using median of sampled probabilities: 0.9608 %
Accuracy on 11 batch using median of sampled probabilities, not considering unclassified examples: 0.9665996 %
Accuracy on 12 batch using median of sampled probabilities: 0.9492 %
Accuracy on 12 batch using median of sampled probabilities, not considering unclassified examples: 0.9576271 %
Accuracy on 13 batch using median of sampled probabilities: 0.9408 %
Accuracy on 13 batch using median of sampled probabilities, not considering unclassified examples: 0.94609815 %
Accuracy on 14 batch using median of sampled probabilities: 0.9544 %
Accuracy on 14 batch using median of sampled probabilities, not considering unclassified examples: 0.95977473 %
Accuracy on 15 batch using median of sampled probabilities: 0.94 %
Accuracy on 15 batch using median of sampled probabilities, not considering unclassified examples: 0.94949496 %
Accuracy on 16 batch using median of sampled probabilities: 0.9704 %
Accuracy on 16 batch using median of sampled probabilities, not considering unclassified examples: 0.97429717 %
Accuracy on 17 batch using median of sampled probabilities: 0.916 %
Accuracy on 17 batch using median of sampled probabilities, not considering unclassified examples: 0.92487884 %
Accuracy on 18 batch using median of sampled probabilities: 0.926 %
Accuracy on 18 batch using median of sampled probabilities, not considering unclassified examples: 0.93271554 %
Accuracy on 19 batch using median of sampled probabilities: 0.9496 %
Accuracy on 19 batch using median of sampled probabilities, not considering unclassified examples: 0.9507409 %
Accuracy on 20 batch using median of sampled probabilities: 0.9596 %
Accuracy on 20 batch using median of sampled probabilities, not considering unclassified examples: 0.96616995 %
Accuracy on 21 batch using median of sampled probabilities: 0.9404 %
Accuracy on 21 batch using median of sampled probabilities, not considering unclassified examples: 0.948749 %
Accuracy on 22 batch using median of sampled probabilities: 0.9336 %
Accuracy on 22 batch using median of sampled probabilities, not considering unclassified examples: 0.94341147 %
Accuracy on 23 batch using median of sampled probabilities: 0.916 %
Accuracy on 23 batch using median of sampled probabilities, not considering unclassified examples: 0.9211585 %
Accuracy on 24 batch using median of sampled probabilities: 0.9292 %
Accuracy on 24 batch using median of sampled probabilities, not considering unclassified examples: 0.9374496 %
Accuracy on 25 batch using median of sampled probabilities: 0.9312 %
Accuracy on 25 batch using median of sampled probabilities, not considering unclassified examples: 0.9356913 %
Accuracy on 26 batch using median of sampled probabilities: 0.9396 %
Accuracy on 26 batch using median of sampled probabilities, not considering unclassified examples: 0.9433735 %
Accuracy on 27 batch using median of sampled probabilities: 0.9532 %
Accuracy on 27 batch using median of sampled probabilities, not considering unclassified examples: 0.9628283 %
Accuracy on 28 batch using median of sampled probabilities: 0.938 %
Accuracy on 28 batch using median of sampled probabilities, not considering unclassified examples: 0.94404185 %
Accuracy on 29 batch using median of sampled probabilities: 0.9172 %
Accuracy on 29 batch using median of sampled probabilities, not considering unclassified examples: 0.9257166 %
Accuracy on 30 batch using median of sampled probabilities: 0.9416 %
Accuracy on 30 batch using median of sampled probabilities, not considering unclassified examples: 0.94957644 %
Accuracy on 31 batch using median of sampled probabilities: 0.9512 %
Accuracy on 31 batch using median of sampled probabilities, not considering unclassified examples: 0.9573269 %
Accuracy on 32 batch using median of sampled probabilities: 0.9344 %
Accuracy on 32 batch using median of sampled probabilities, not considering unclassified examples: 0.9411765 %
Accuracy on 33 batch using median of sampled probabilities: 0.928 %
Accuracy on 33 batch using median of sampled probabilities, not considering unclassified examples: 0.9343536 %
Accuracy on 34 batch using median of sampled probabilities: 0.9152 %
Accuracy on 34 batch using median of sampled probabilities, not considering unclassified examples: 0.92258066 %
Accuracy on 35 batch using median of sampled probabilities: 0.9344 %
Accuracy on 35 batch using median of sampled probabilities, not considering unclassified examples: 0.9430763 %
Accuracy on 36 batch using median of sampled probabilities: 0.92 %
Accuracy on 36 batch using median of sampled probabilities, not considering unclassified examples: 0.924809 %
Accuracy on 37 batch using median of sampled probabilities: 0.9388 %
Accuracy on 37 batch using median of sampled probabilities, not considering unclassified examples: 0.9440869 %
Accuracy on 38 batch using median of sampled probabilities: 0.9228 %
Accuracy on 38 batch using median of sampled probabilities, not considering unclassified examples: 0.92949235 %
Accuracy on 39 batch using median of sampled probabilities: 0.9324 %
Accuracy on 39 batch using median of sampled probabilities, not considering unclassified examples: 0.9421989 %
Accuracy on 40 batch using median of sampled probabilities: 0.932 %
Accuracy on 40 batch using median of sampled probabilities, not considering unclassified examples: 0.93536735 %
Accuracy on 41 batch using median of sampled probabilities: 0.9496 %
Accuracy on 41 batch using median of sampled probabilities, not considering unclassified examples: 0.95456374 %
Accuracy on 42 batch using median of sampled probabilities: 0.9148 %
Accuracy on 42 batch using median of sampled probabilities, not considering unclassified examples: 0.9247877 %
Accuracy on 43 batch using median of sampled probabilities: 0.9136 %
Accuracy on 43 batch using median of sampled probabilities, not considering unclassified examples: 0.9288329 %
Accuracy on 44 batch using median of sampled probabilities: 0.9372 %
Accuracy on 44 batch using median of sampled probabilities, not considering unclassified examples: 0.9481991 %
Accuracy on 45 batch using median of sampled probabilities: 0.9516 %
Accuracy on 45 batch using median of sampled probabilities, not considering unclassified examples: 0.96160066 %
Accuracy on 46 batch using median of sampled probabilities: 0.9388 %
Accuracy on 46 batch using median of sampled probabilities, not considering unclassified examples: 0.9418138 %
Accuracy on 47 batch using median of sampled probabilities: 0.9532 %
Accuracy on 47 batch using median of sampled probabilities, not considering unclassified examples: 0.96166265 %
Accuracy on 48 batch using median of sampled probabilities: 0.9208 %
Accuracy on 48 batch using median of sampled probabilities, not considering unclassified examples: 0.923756 %
Accuracy on 49 batch using median of sampled probabilities: 0.9256 %
Accuracy on 49 batch using median of sampled probabilities, not considering unclassified examples: 0.93381757 %
-- Accuracy on test set using median of sampled probabilities: 0.9347358 % 

-- Accuracy on test set using median of sampled probabilities, not considering unclassified examples: 0.94184333 % 

Adding Not classified label
/home/master/Desktop/pastırma/BaCoN/testt.py:154: RuntimeWarning: invalid value encountered in divide
  matrix_proportions[i,:] = cm[i,:]/float(cm[i,:].sum())
Warning: Ignoring XDG_SESSION_TYPE=wayland on Gnome. Use QT_QPA_PLATFORM=wayland to run on Wayland anyway.
Qt: Session management error: None of the authentication protocols specified are supported
Saved confusion matrix at models/5_small/cm_frozen_weights.pdf
Saved confusion matrix values at models/5_small/cm_frozen_weights_values.txt