
 -------- Parameters:
bayesian True
test_mode True
n_test_idx 2
seed 1312
fine_tune False
one_vs_all True
c_0 ['lcdm']
c_1 ['dgp', 'fR', 'rand', 'wcdm']
dataset_balanced False
include_last False
log_path 
restore False
fname 5-label
model_name custom
my_path None
DIR data/train_data/
TEST_DIR data/test_data/
models_dir models/
save_ckpt True
out_path_overwrite False
im_depth 500
im_width 1
im_channels 4
swap_axes True
sort_labels True
normalization stdcosmo
sample_pace 4
k_max 2.5
i_max None
add_noise True
n_noisy_samples 10
add_shot True
add_sys True
sigma_sys 5.0
z_bins [0, 1, 2, 3]
n_dense 1
filters [8, 16, 32]
kernel_sizes [10, 5, 2]
strides [2, 2, 1]
pool_sizes [2, 2, 0]
strides_pooling [2, 1, 0]
add_FT_dense False
trainable True
unfreeze False
lr 0.01
drop 0.5
n_epochs 40
val_size 0.15
test_size 0.0
batch_size 2500
patience 100
GPU True
decay 0.95
BatchNorm True
group_lab_dict {'dgp': 'non_lcdm', 'fR': 'non_lcdm', 'rand': 'non_lcdm', 'wcdm': 'non_lcdm', 'lcdm': 'lcdm'}

------------ CREATING DATA GENERATORS ------------
labels : ['lcdm', 'non_lcdm']
Labels encoding: 
{'lcdm': 0, 'non_lcdm': 1}
n_labels : 2
dgp - 18475 training examples
fR - 18475 training examples
lcdm - 18475 training examples
rand - 18475 training examples
wcdm - 18475 training examples

N. of data files: 18475
Choice with seed 1312 
all_index shape for test mode: 8
get_all_indexes labels dict: {'lcdm': 0, 'non_lcdm': 1}
create_generators n_labels: 2
create_generators n_labels_eff: 5
create_generators len_c1: 1
Check for no duplicates in test: (0=ok):
0.0
Check for no duplicates in val: (0=ok):
0
N of files in training set: 4
N of files in validation set: 4
N of files in test set: 0
Check - total: 8
--create_generators, train indexes
batch_size: 200
Train index: [  325  2781  9342 15017]
--create_generators, validation indexes
Validation index: [11211 11610 14145  2102]
len(train_index_1), batch_size, n_labels_eff, n_noisy_samples = 4, 200, 5, 10

--DataGenerator Train
Data Generator Initialization
Using z bins [0, 1, 2, 3]
Specified k_max is 2.5
Corresponding i_max is 100
Closest k to k_max is 2.539859
New data dim: (100, 1)
Final i_max used is 100
one_vs_all: True
dataset_balanced: False
base_case_dataset: True
N. classes: 5
N. n_classes in output: 2
list_IDs length: 4
n_indexes (n of file IDs read for each batch): 4
batch size: 200
n_batches : 1
For each batch we read 4 file IDs
For each file ID we have 5 labels
For each ID, label we have 10 realizations of noise
In total, for each batch we have 200 training examples
Input batch size: 200
N of batches to cover all file IDs: 1

--DataGenerator Validation
Data Generator Initialization
Using z bins [0, 1, 2, 3]
Specified k_max is 2.5
Corresponding i_max is 100
Closest k to k_max is 2.539859
New data dim: (100, 1)
Final i_max used is 100
one_vs_all: True
dataset_balanced: False
base_case_dataset: True
N. classes: 5
N. n_classes in output: 2
list_IDs length: 4
n_indexes (n of file IDs read for each batch): 4
batch size: 200
n_batches : 1
For each batch we read 4 file IDs
For each file ID we have 5 labels
For each ID, label we have 10 realizations of noise
In total, for each batch we have 200 training examples
Input batch size: 200
N of batches to cover all file IDs: 1
------------ DONE ------------

------------ BUILDING MODEL ------------
Input shape (100, 4)
using 1D layers and 4 channels
Expected output dimension of layer conv1d_flipout: 46.0
Expected output dimension of layer max_pooling1d: 23.0
Expected output dimension of layer conv1d_flipout_1: 10.0
Expected output dimension of layer max_pooling1d_1: 9.0
Expected output dimension of layer conv1d_flipout_2: 8.0
Model: "model"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_1 (InputLayer)        [(None, 100, 4)]          0         
                                                                 
 conv1d_flipout (Conv1DFlipo  (None, 46, 8)            648       
 ut)                                                             
                                                                 
 max_pooling1d (MaxPooling1D  (None, 23, 8)            0         
 )                                                               
                                                                 
 batch_normalization (BatchN  (None, 23, 8)            32        
 ormalization)                                                   
                                                                 
 conv1d_flipout_1 (Conv1DFli  (None, 10, 16)           1296      
 pout)                                                           
                                                                 
 max_pooling1d_1 (MaxPooling  (None, 9, 16)            0         
 1D)                                                             
                                                                 
 batch_normalization_1 (Batc  (None, 9, 16)            64        
 hNormalization)                                                 
                                                                 
 conv1d_flipout_2 (Conv1DFli  (None, 8, 32)            2080      
 pout)                                                           
                                                                 
 batch_normalization_2 (Batc  (None, 8, 32)            128       
 hNormalization)                                                 
                                                                 
 global_average_pooling1d (G  (None, 32)               0         
 lobalAveragePooling1D)                                          
                                                                 
 dense_flipout (DenseFlipout  (None, 32)               2080      
 )                                                               
                                                                 
 batch_normalization_3 (Batc  (None, 32)               128       
 hNormalization)                                                 
                                                                 
 dense_flipout_1 (DenseFlipo  (None, 2)                130       
 ut)                                                             
                                                                 
=================================================================
Total params: 6,586
Trainable params: 6,410
Non-trainable params: 176
_________________________________________________________________
None
GPU device not found ! Device: 
------------ TRAINING ------------

Features shape: (200, 100, 4)
Labels shape: (200, 2)
Initializing checkpoint from scratch.
Epoch 0
Validation loss decreased. Saved checkpoint for step 1: models/5-label_test/tf_ckpts_test/ckpt_test-1
Time:  2.94s, ---- Loss: 39.6760, Acc.: 0.4550, Val. Loss: 39.4337, Val. Acc.: 0.4950

Epoch 1
Validation loss decreased. Saved checkpoint for step 2: models/5-label_test/tf_ckpts_test/ckpt_test-2
Time:  0.22s, ---- Loss: 39.4738, Acc.: 0.5350, Val. Loss: 39.2777, Val. Acc.: 0.7150

Epoch 2
Validation loss decreased. Saved checkpoint for step 3: models/5-label_test/tf_ckpts_test/ckpt_test-3
Time:  0.29s, ---- Loss: 39.2658, Acc.: 0.5300, Val. Loss: 39.1323, Val. Acc.: 0.7750

Epoch 3
Validation loss decreased. Saved checkpoint for step 4: models/5-label_test/tf_ckpts_test/ckpt_test-4
Time:  0.31s, ---- Loss: 39.0681, Acc.: 0.6750, Val. Loss: 38.9962, Val. Acc.: 0.8000

Epoch 4
Validation loss decreased. Saved checkpoint for step 5: models/5-label_test/tf_ckpts_test/ckpt_test-5
Time:  0.37s, ---- Loss: 38.9455, Acc.: 0.6550, Val. Loss: 38.8692, Val. Acc.: 0.8000

Epoch 5
Validation loss decreased. Saved checkpoint for step 6: models/5-label_test/tf_ckpts_test/ckpt_test-6
Time:  0.29s, ---- Loss: 38.8148, Acc.: 0.6400, Val. Loss: 38.7392, Val. Acc.: 0.8000

Epoch 6
Validation loss decreased. Saved checkpoint for step 7: models/5-label_test/tf_ckpts_test/ckpt_test-7
Time:  0.30s, ---- Loss: 38.6613, Acc.: 0.6900, Val. Loss: 38.6217, Val. Acc.: 0.8000

Epoch 7
Validation loss decreased. Saved checkpoint for step 8: models/5-label_test/tf_ckpts_test/ckpt_test-8
Time:  0.27s, ---- Loss: 38.5286, Acc.: 0.7650, Val. Loss: 38.5113, Val. Acc.: 0.8000

Epoch 8
Validation loss decreased. Saved checkpoint for step 9: models/5-label_test/tf_ckpts_test/ckpt_test-9
Time:  0.37s, ---- Loss: 38.3698, Acc.: 0.7950, Val. Loss: 38.4012, Val. Acc.: 0.8000

Epoch 9
Validation loss decreased. Saved checkpoint for step 10: models/5-label_test/tf_ckpts_test/ckpt_test-10
Time:  0.24s, ---- Loss: 38.2530, Acc.: 0.7950, Val. Loss: 38.2991, Val. Acc.: 0.8000

Epoch 10
Validation loss decreased. Saved checkpoint for step 11: models/5-label_test/tf_ckpts_test/ckpt_test-11
Time:  0.19s, ---- Loss: 38.1303, Acc.: 0.8050, Val. Loss: 38.2006, Val. Acc.: 0.8000

Epoch 11
Validation loss decreased. Saved checkpoint for step 12: models/5-label_test/tf_ckpts_test/ckpt_test-12
Time:  0.31s, ---- Loss: 38.0238, Acc.: 0.8250, Val. Loss: 38.1064, Val. Acc.: 0.8000

Epoch 12
Validation loss decreased. Saved checkpoint for step 13: models/5-label_test/tf_ckpts_test/ckpt_test-13
Time:  0.29s, ---- Loss: 37.9311, Acc.: 0.8350, Val. Loss: 38.0185, Val. Acc.: 0.8000

Epoch 13
Validation loss decreased. Saved checkpoint for step 14: models/5-label_test/tf_ckpts_test/ckpt_test-14
Time:  0.30s, ---- Loss: 37.8211, Acc.: 0.8700, Val. Loss: 37.9340, Val. Acc.: 0.8000

Epoch 14
Validation loss decreased. Saved checkpoint for step 15: models/5-label_test/tf_ckpts_test/ckpt_test-15
Time:  0.38s, ---- Loss: 37.7202, Acc.: 0.8850, Val. Loss: 37.8532, Val. Acc.: 0.8000

Epoch 15
Validation loss decreased. Saved checkpoint for step 16: models/5-label_test/tf_ckpts_test/ckpt_test-16
Time:  0.32s, ---- Loss: 37.6678, Acc.: 0.8750, Val. Loss: 37.7775, Val. Acc.: 0.8000

Epoch 16
Validation loss decreased. Saved checkpoint for step 17: models/5-label_test/tf_ckpts_test/ckpt_test-17
Time:  0.34s, ---- Loss: 37.5583, Acc.: 0.9000, Val. Loss: 37.7035, Val. Acc.: 0.8000

Epoch 17
Validation loss decreased. Saved checkpoint for step 18: models/5-label_test/tf_ckpts_test/ckpt_test-18
Time:  0.34s, ---- Loss: 37.5194, Acc.: 0.8800, Val. Loss: 37.6371, Val. Acc.: 0.8000

Epoch 18
Validation loss decreased. Saved checkpoint for step 19: models/5-label_test/tf_ckpts_test/ckpt_test-19
Time:  0.35s, ---- Loss: 37.3908, Acc.: 0.9200, Val. Loss: 37.5741, Val. Acc.: 0.8000

Epoch 19
Validation loss decreased. Saved checkpoint for step 20: models/5-label_test/tf_ckpts_test/ckpt_test-20
Time:  0.17s, ---- Loss: 37.3203, Acc.: 0.9200, Val. Loss: 37.5113, Val. Acc.: 0.8000

Epoch 20
Validation loss decreased. Saved checkpoint for step 21: models/5-label_test/tf_ckpts_test/ckpt_test-21
Time:  0.23s, ---- Loss: 37.2718, Acc.: 0.9150, Val. Loss: 37.4556, Val. Acc.: 0.8000

Epoch 21
Validation loss decreased. Saved checkpoint for step 22: models/5-label_test/tf_ckpts_test/ckpt_test-22
Time:  0.26s, ---- Loss: 37.1993, Acc.: 0.9250, Val. Loss: 37.3995, Val. Acc.: 0.8000

Epoch 22
Validation loss decreased. Saved checkpoint for step 23: models/5-label_test/tf_ckpts_test/ckpt_test-23
Time:  0.32s, ---- Loss: 37.1327, Acc.: 0.9250, Val. Loss: 37.3430, Val. Acc.: 0.8000

Epoch 23
Validation loss decreased. Saved checkpoint for step 24: models/5-label_test/tf_ckpts_test/ckpt_test-24
Time:  0.23s, ---- Loss: 37.0794, Acc.: 0.9250, Val. Loss: 37.2944, Val. Acc.: 0.8000

Epoch 24
Validation loss decreased. Saved checkpoint for step 25: models/5-label_test/tf_ckpts_test/ckpt_test-25
Time:  0.34s, ---- Loss: 37.0086, Acc.: 0.9500, Val. Loss: 37.2448, Val. Acc.: 0.8000

Epoch 25
Validation loss decreased. Saved checkpoint for step 26: models/5-label_test/tf_ckpts_test/ckpt_test-26
Time:  0.29s, ---- Loss: 36.9800, Acc.: 0.9400, Val. Loss: 37.2027, Val. Acc.: 0.8000

Epoch 26
Validation loss decreased. Saved checkpoint for step 27: models/5-label_test/tf_ckpts_test/ckpt_test-27
Time:  0.26s, ---- Loss: 36.9244, Acc.: 0.9400, Val. Loss: 37.1658, Val. Acc.: 0.8000

Epoch 27
Validation loss decreased. Saved checkpoint for step 28: models/5-label_test/tf_ckpts_test/ckpt_test-28
Time:  0.27s, ---- Loss: 36.8901, Acc.: 0.9400, Val. Loss: 37.1233, Val. Acc.: 0.8000

Epoch 28
Validation loss decreased. Saved checkpoint for step 29: models/5-label_test/tf_ckpts_test/ckpt_test-29
Time:  0.33s, ---- Loss: 36.7989, Acc.: 0.9700, Val. Loss: 37.0948, Val. Acc.: 0.8000

Epoch 29
Validation loss decreased. Saved checkpoint for step 30: models/5-label_test/tf_ckpts_test/ckpt_test-30
Time:  0.19s, ---- Loss: 36.8037, Acc.: 0.9400, Val. Loss: 37.0583, Val. Acc.: 0.8000

Epoch 30
Validation loss decreased. Saved checkpoint for step 31: models/5-label_test/tf_ckpts_test/ckpt_test-31
Time:  0.24s, ---- Loss: 36.7715, Acc.: 0.9300, Val. Loss: 37.0221, Val. Acc.: 0.8000

Epoch 31
Validation loss decreased. Saved checkpoint for step 32: models/5-label_test/tf_ckpts_test/ckpt_test-32
Time:  0.36s, ---- Loss: 36.7027, Acc.: 0.9650, Val. Loss: 36.9919, Val. Acc.: 0.8000

Epoch 32
Validation loss decreased. Saved checkpoint for step 33: models/5-label_test/tf_ckpts_test/ckpt_test-33
Time:  0.27s, ---- Loss: 36.6985, Acc.: 0.9350, Val. Loss: 36.9629, Val. Acc.: 0.8000

Epoch 33
Validation loss decreased. Saved checkpoint for step 34: models/5-label_test/tf_ckpts_test/ckpt_test-34
Time:  0.24s, ---- Loss: 36.6388, Acc.: 0.9700, Val. Loss: 36.9361, Val. Acc.: 0.8000

Epoch 34
Validation loss decreased. Saved checkpoint for step 35: models/5-label_test/tf_ckpts_test/ckpt_test-35
Time:  0.31s, ---- Loss: 36.6096, Acc.: 0.9700, Val. Loss: 36.9111, Val. Acc.: 0.8000

Epoch 35
Validation loss decreased. Saved checkpoint for step 36: models/5-label_test/tf_ckpts_test/ckpt_test-36
Time:  0.34s, ---- Loss: 36.5868, Acc.: 0.9700, Val. Loss: 36.8783, Val. Acc.: 0.8000

Epoch 36
Validation loss decreased. Saved checkpoint for step 37: models/5-label_test/tf_ckpts_test/ckpt_test-37
Time:  0.29s, ---- Loss: 36.5293, Acc.: 0.9800, Val. Loss: 36.8615, Val. Acc.: 0.8000

Epoch 37
Validation loss decreased. Saved checkpoint for step 38: models/5-label_test/tf_ckpts_test/ckpt_test-38
Time:  0.30s, ---- Loss: 36.5156, Acc.: 0.9750, Val. Loss: 36.8326, Val. Acc.: 0.8000

Epoch 38
Validation loss decreased. Saved checkpoint for step 39: models/5-label_test/tf_ckpts_test/ckpt_test-39
Time:  0.32s, ---- Loss: 36.5224, Acc.: 0.9600, Val. Loss: 36.8155, Val. Acc.: 0.8000

Epoch 39
Validation loss decreased. Saved checkpoint for step 40: models/5-label_test/tf_ckpts_test/ckpt_test-40
Time:  0.28s, ---- Loss: 36.4611, Acc.: 0.9800, Val. Loss: 36.7974, Val. Acc.: 0.8000

Saving at models/5-label_test/hist.png
